# æ¨¡å—å¯¼å…¥é”™è¯¯ä¿®å¤æŠ¥å‘Š

**æ—¥æœŸ**: 2025-10-22  
**é—®é¢˜**: AME æ¨¡å—å¯¼å…¥é”™è¯¯  
**æ ¹æœ¬åŸå› **: backend å·²åˆ é™¤ï¼Œä½† AME ä»å¼•ç”¨æ—§çš„ backend æ¨¡å—

---

## ğŸ” é—®é¢˜åˆ†æ

### é”™è¯¯ç±»å‹

1. **ModuleNotFoundError**: `ame.mem.memory_manager` ä¸å­˜åœ¨
2. **ModuleNotFoundError**: `app.core.logger` ä¸å­˜åœ¨  
3. **ModuleNotFoundError**: `app.core.config` ä¸å­˜åœ¨

### æ ¹æœ¬åŸå› 

åœ¨é¡¹ç›®æ¶æ„ä¼˜åŒ–ä¸­ï¼š
- âœ… åˆ é™¤äº† `backend/` æ–‡ä»¶å¤¹
- âœ… Streamlit ç›´æ¥è°ƒç”¨ AME æ¨¡å—
- âŒ ä½† AME å†…éƒ¨ä»å¼•ç”¨ `app.core.*`ï¼ˆbackend çš„æ¨¡å—ï¼‰

---

## âœ… è§£å†³æ–¹æ¡ˆ

### ä¿®å¤ç­–ç•¥

**å»é™¤å¯¹ backend çš„ä¾èµ–**ï¼Œä½¿ AME æˆä¸ºçœŸæ­£ç‹¬ç«‹çš„æŠ€æœ¯æ¨¡å—å¼•æ“ã€‚

---

### ä¿®å¤è¯¦æƒ…

#### 1. ä¿®å¤ `ame/mem/__init__.py`

**é—®é¢˜**: å¯¼å…¥ä¸å­˜åœ¨çš„æ¨¡å—
```python
from .memory_manager import MemoryManager  # âŒ æ–‡ä»¶ä¸å­˜åœ¨
from .conversation_tracker import ConversationTracker  # âŒ æ–‡ä»¶ä¸å­˜åœ¨
```

**è§£å†³**:
```python
# åªå¯¼å‡ºå®é™…å­˜åœ¨çš„æ¨¡å—
from .mimic_engine import MimicEngine

__all__ = ['MimicEngine']
```

**å½±å“**: âœ… æ— ï¼Œè¿™äº›æ¨¡å—æœ¬æ¥å°±æœªå®ç°

---

#### 2. ä¿®å¤ `ame/data_processor/async_processor.py`

**é—®é¢˜**: å¯¼å…¥ backend çš„ logger
```python
from app.core.logger import get_logger  # âŒ backend å·²åˆ é™¤
logger = get_logger("async_processor")
```

**è§£å†³**: ä½¿ç”¨æ ‡å‡† logging
```python
import logging
logger = logging.getLogger(__name__)
```

**å½±å“**: âœ… åŠŸèƒ½å®Œå…¨ç›¸åŒï¼Œä½¿ç”¨ Python æ ‡å‡†åº“

---

#### 3. ä¿®å¤ `ame/llm_caller/caller.py`

**é—®é¢˜**: ä¾èµ– backend é…ç½®
```python
from app.core.config import settings  # âŒ backend å·²åˆ é™¤

def __init__(self, ...):
    api_key = os.getenv("OPENAI_API_KEY", settings.OPENAI_API_KEY)
```

**è§£å†³**: å†…ç½®é»˜è®¤é…ç½® + æ„é€ å‚æ•°
```python
# é»˜è®¤é…ç½®
DEFAULT_CONFIG = {
    "OPENAI_API_KEY": "",
    "OPENAI_BASE_URL": "https://api.openai.com/v1",
    "OPENAI_MODEL": "gpt-3.5-turbo"
}

def __init__(self, api_key: str = None, base_url: str = None, model: str = None, ...):
    self.api_key = api_key or os.getenv("OPENAI_API_KEY", DEFAULT_CONFIG["OPENAI_API_KEY"])
    self.base_url = base_url or os.getenv("OPENAI_BASE_URL", DEFAULT_CONFIG["OPENAI_BASE_URL"])
    self.model = model or os.getenv("OPENAI_MODEL", DEFAULT_CONFIG["OPENAI_MODEL"])
```

**ä¼˜åŠ¿**:
- âœ… æ›´çµæ´»ï¼šæ”¯æŒç›´æ¥ä¼ å‚
- âœ… æ›´ç‹¬ç«‹ï¼šä¸ä¾èµ–å¤–éƒ¨é…ç½®
- âœ… æ›´æ¸…æ™°ï¼šé…ç½®æ¥æºä¸€ç›®äº†ç„¶

---

#### 4. ä¿®å¤ `ame/vector_store/store.py`

**é—®é¢˜**: ä¾èµ– backend é…ç½®
```python
from app.core.config import settings as app_settings  # âŒ

def __init__(self):
    path = app_settings.VECTOR_DB_PATH
```

**è§£å†³**: é»˜è®¤è·¯å¾„ + æ„é€ å‚æ•°
```python
# é»˜è®¤é…ç½®
DEFAULT_VECTOR_DB_PATH = "./data/vector_store"

def __init__(self, db_path: str = None):
    path = db_path or os.getenv("VECTOR_DB_PATH", DEFAULT_VECTOR_DB_PATH)
    os.makedirs(path, exist_ok=True)
```

**ä¼˜åŠ¿**:
- âœ… æ”¯æŒè‡ªå®šä¹‰è·¯å¾„
- âœ… è‡ªåŠ¨åˆ›å»ºç›®å½•
- âœ… ç¯å¢ƒå˜é‡ä¼˜å…ˆ

---

## ğŸ“Š ä¿®æ”¹æ–‡ä»¶æ¸…å•

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | çŠ¶æ€ |
|------|---------|------|
| ame/mem/__init__.py | ç§»é™¤ä¸å­˜åœ¨çš„å¯¼å…¥ | âœ… å·²ä¿®å¤ |
| ame/data_processor/async_processor.py | ä½¿ç”¨æ ‡å‡† logging | âœ… å·²ä¿®å¤ |
| ame/llm_caller/caller.py | å†…ç½®é…ç½® + æ„é€ å‚æ•° | âœ… å·²ä¿®å¤ |
| ame/vector_store/store.py | é»˜è®¤è·¯å¾„ + æ„é€ å‚æ•° | âœ… å·²ä¿®å¤ |

---

## ğŸ¯ æ¶æ„æ”¹è¿›

### ä¿®å¤å‰
```
AME æ¨¡å— (ä¾èµ– backend.core)
    â†“
backend.core.config
backend.core.logger
```
- âŒ ç´§è€¦åˆ
- âŒ æ— æ³•ç‹¬ç«‹ä½¿ç”¨

### ä¿®å¤å
```
AME æ¨¡å— (å®Œå…¨ç‹¬ç«‹)
    â†“
å†…ç½®é…ç½® + ç¯å¢ƒå˜é‡ + æ„é€ å‚æ•°
Python æ ‡å‡†åº“
```
- âœ… æ¾è€¦åˆ
- âœ… å¯ç‹¬ç«‹ä½¿ç”¨
- âœ… æ›´çµæ´»

---

## âœ¨ ä¼˜åŠ¿

1. **çœŸæ­£ç‹¬ç«‹**: AME ä¸å†ä¾èµ–ä»»ä½•å¤–éƒ¨æ¨¡å—
2. **æ›´æ˜“ä½¿ç”¨**: å¯ä»¥åœ¨ä»»ä½• Python é¡¹ç›®ä¸­ç›´æ¥ä½¿ç”¨
3. **é…ç½®çµæ´»**: æ”¯æŒå¤šç§é…ç½®æ–¹å¼ï¼š
   - ç¯å¢ƒå˜é‡
   - æ„é€ å‚æ•°
   - é»˜è®¤å€¼
4. **ç¬¦åˆè§„èŒƒ**: æŠ€æœ¯æ¨¡å—åº”è¯¥æ˜¯ç‹¬ç«‹çš„ã€å¯å¤ç”¨çš„

---

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### LLMCaller (ä¿®å¤å)

```python
from ame.llm_caller import LLMCaller

# æ–¹å¼1: ä»ç¯å¢ƒå˜é‡è¯»å–
llm = LLMCaller()

# æ–¹å¼2: æ˜¾å¼ä¼ å‚
llm = LLMCaller(
    api_key="sk-...",
    base_url="https://api.openai.com/v1",
    model="gpt-4"
)

# æ–¹å¼3: æ··åˆ
llm = LLMCaller(api_key="sk-...")  # å…¶ä»–ä½¿ç”¨é»˜è®¤å€¼
```

### ChromaVectorStore (ä¿®å¤å)

```python
from ame.vector_store import VectorStoreFactory

# æ–¹å¼1: ä½¿ç”¨é»˜è®¤è·¯å¾„ ./data/vector_store
store = VectorStoreFactory.create("chroma")

# æ–¹å¼2: è‡ªå®šä¹‰è·¯å¾„
store = VectorStoreFactory.create("chroma", db_path="/custom/path")
```

---

## ğŸ“‹ éªŒè¯æ¸…å•

- [x] æ‰€æœ‰ `from app.*` å¯¼å…¥å·²ç§»é™¤
- [x] æ‰€æœ‰ `from backend.*` å¯¼å…¥å·²ç§»é™¤
- [x] AME æ¨¡å—å¯ç‹¬ç«‹è¿è¡Œ
- [x] ä¸ç ´åç°æœ‰åŠŸèƒ½
- [x] æ”¯æŒç¯å¢ƒå˜é‡é…ç½®
- [x] æ”¯æŒæ„é€ å‚æ•°é…ç½®

---

## ğŸ‰ æ€»ç»“

é€šè¿‡è¿™æ¬¡ä¿®å¤ï¼š
1. âœ… **è§£å†³äº†**æ‰€æœ‰æ¨¡å—å¯¼å…¥é”™è¯¯
2. âœ… **å®ç°äº†** AME æ¨¡å—çš„çœŸæ­£ç‹¬ç«‹
3. âœ… **æå‡äº†**ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œå¯å¤ç”¨æ€§
4. âœ… **ç¬¦åˆäº†**é¡¹ç›®æ¶æ„è®¾è®¡è§„èŒƒ

**AME ç°åœ¨æ˜¯ä¸€ä¸ªçœŸæ­£ç‹¬ç«‹çš„æŠ€æœ¯æ¨¡å—å¼•æ“ï¼** ğŸŠ

---

**ä¿®å¤ç‰ˆæœ¬**: v0.5.0  
**ç”Ÿæˆæ—¶é—´**: 2025-10-22
