"""
MEM å¯¹è¯é¡µé¢ - æ¨¡ä»¿ç”¨æˆ·è¯´è¯é£æ ¼
"""

import streamlit as st
import sys
import os
import asyncio

sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from ame.mem.mimic_engine import MimicEngine
from ame.llm_caller.caller import LLMCaller


def show():
    """æ˜¾ç¤º MEM å¯¹è¯é¡µé¢"""
    
    st.title("ğŸ’¬ MEM å¯¹è¯")
    
    st.markdown("""
    ä¸ AI åˆ†èº«å¯¹è¯ï¼Œå®ƒä¼šæ¨¡ä»¿ä½ çš„è¯´è¯é£æ ¼ã€‚ä¸Šä¼ èŠå¤©è®°å½•è®©å®ƒå­¦ä¹ ï¼Œå¯¹è¯ä¼šè¢«è®°å½•ä»¥æŒç»­æ”¹è¿›ã€‚
    """)
    
    if not st.session_state.is_configured:
        st.warning("âš ï¸ è¯·å…ˆåœ¨é…ç½®é¡µé¢è®¾ç½® API Key")
        return
    
    # åˆ›å»ºæ¨¡ä»¿å¼•æ“
    if 'mimic_engine' not in st.session_state:
        llm_caller = LLMCaller(
            api_key=st.session_state.api_key,
            base_url=st.session_state.api_base_url,
            model=st.session_state.model
        )
        st.session_state.mimic_engine = MimicEngine(llm_caller=llm_caller)
    
    engine = st.session_state.mimic_engine
    
    # å¿«é€Ÿç»Ÿè®¡å¡ç‰‡
    stats = asyncio.run(engine.vector_store.get_statistics())
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ’¬ æ€»è®°å¿†æ•°", stats.get('count', 0))
    
    with col2:
        st.metric("ğŸ·ï¸ æ¥æºç±»å‹", len(stats.get('sources', {})))
    
    with col3:
        chat_count = len(st.session_state.get('mem_chat_history', []))
        st.metric("ğŸ“ å½“å‰å¯¹è¯", f"{chat_count} æ¡")
    
    with col4:
        if st.button("ğŸ§  ç®¡ç†è®°å¿†", use_container_width=True):
            st.session_state.navigation = "ğŸ§  è®°å¿†ç®¡ç†"
            st.rerun()
    
    st.markdown("---")
    
    # æ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["ğŸ’¬ å¯¹è¯", "ğŸ“š å­¦ä¹ ææ–™"])
    
    with tab1:
        show_chat_tab(engine)
    
    with tab2:
        show_learning_tab(engine)


def show_chat_tab(engine):
    """å¯¹è¯æ ‡ç­¾é¡µ"""
    
    st.subheader("ğŸ’¬ ä¸ AI åˆ†èº«å¯¹è¯")
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    if 'mem_chat_history' not in st.session_state:
        st.session_state.mem_chat_history = []
    
    # èŠå¤©å®¹å™¨
    chat_container = st.container()
    
    with chat_container:
        for message in st.session_state.mem_chat_history:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    # è¾“å…¥æ¡†
    user_input = st.chat_input("è¾“å…¥æ¶ˆæ¯...")
    
    if user_input:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        st.session_state.mem_chat_history.append({
            "role": "user",
            "content": user_input
        })
        
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with chat_container:
            with st.chat_message("user"):
                st.markdown(user_input)
        
        # ç”Ÿæˆå›å¤ï¼ˆæµå¼ï¼‰
        with chat_container:
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                
                # æµå¼ç”Ÿæˆ
                async def generate_stream():
                    nonlocal full_response
                    async for chunk in engine.generate_response_stream(
                        prompt=user_input,
                        temperature=0.8,
                        use_history=True
                    ):
                        full_response += chunk
                        message_placeholder.markdown(full_response + "â–Œ")
                    
                    message_placeholder.markdown(full_response)
                    return full_response
                
                # è¿è¡Œå¼‚æ­¥ç”Ÿæˆ
                response = asyncio.run(generate_stream())
        
        # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
        st.session_state.mem_chat_history.append({
            "role": "assistant",
            "content": response
        })
        
        # å­¦ä¹ è¿™æ¬¡å¯¹è¯
        asyncio.run(engine.learn_from_conversation(
            user_message=user_input,
            context=response
        ))
        
        st.rerun()
    
    # æ¸…ç©ºå¯¹è¯å†å²æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
        st.session_state.mem_chat_history = []
        st.rerun()


def show_learning_tab(engine):
    """å­¦ä¹ ææ–™æ ‡ç­¾é¡µ"""
    
    st.subheader("ğŸ“š ä¸Šä¼ èŠå¤©è®°å½•")
    
    st.markdown("""
    ä¸Šä¼ ä½ çš„èŠå¤©è®°å½•æ–‡æœ¬æ–‡ä»¶ï¼Œè®© AI å­¦ä¹ ä½ çš„è¯´è¯é£æ ¼ã€‚
    æ”¯æŒæ ¼å¼ï¼š
    - çº¯æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€æ¡æ¶ˆæ¯ï¼‰
    - JSON æ ¼å¼çš„èŠå¤©è®°å½•
    """)
    
    uploaded_file = st.file_uploader(
        "é€‰æ‹©èŠå¤©è®°å½•æ–‡ä»¶",
        type=['txt', 'json'],
        help="ä¸Šä¼ èŠå¤©è®°å½•æ–‡æœ¬æ–‡ä»¶"
    )
    
    if uploaded_file:
        content = uploaded_file.read().decode('utf-8')
        
        st.text_area(
            "é¢„è§ˆå†…å®¹",
            value=content[:500] + "..." if len(content) > 500 else content,
            height=200,
            disabled=True
        )
        
        if st.button("ğŸ“š å¼€å§‹å­¦ä¹ ", type="primary"):
            with st.spinner("å­¦ä¹ ä¸­..."):
                # ç®€å•å¤„ç†ï¼šæŒ‰è¡Œåˆ†å‰²
                lines = content.split('\n')
                messages = [line.strip() for line in lines if line.strip()]
                
                progress_bar = st.progress(0)
                
                for idx, msg in enumerate(messages):
                    asyncio.run(engine.learn_from_conversation(
                        user_message=msg,
                        metadata={"source": "uploaded_chat"}
                    ))
                    progress_bar.progress((idx + 1) / len(messages))
                
                progress_bar.empty()
                st.success(f"âœ… å·²å­¦ä¹  {len(messages)} æ¡æ¶ˆæ¯ï¼")
    
    st.markdown("---")
    
    # æ‰‹åŠ¨è¾“å…¥å­¦ä¹ ææ–™
    st.subheader("âœï¸ æ‰‹åŠ¨è¾“å…¥")
    
    manual_text = st.text_area(
        "è¾“å…¥ä¸€æ®µä½ è¯´è¿‡çš„è¯",
        height=150,
        placeholder="è¾“å…¥ä½ çš„èŠå¤©è®°å½•ã€æ—¥è®°ã€æƒ³æ³•..."
    )
    
    if st.button("ğŸ’¾ ä¿å­˜å¹¶å­¦ä¹ "):
        if manual_text.strip():
            asyncio.run(engine.learn_from_conversation(
                user_message=manual_text,
                metadata={"source": "manual_input"}
            ))
            st.success("âœ… å·²å­¦ä¹ ï¼")
        else:
            st.error("è¯·è¾“å…¥å†…å®¹")
