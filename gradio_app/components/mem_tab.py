"""
MEM å¯¹è¯é¡µé¢ç»„ä»¶ - æ”¯æŒæµå¼è¾“å‡º
"""

import gradio as gr
import sys
import os
import asyncio

sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from ame.mem.mimic_engine import MimicEngine
from ame.llm_caller.caller import LLMCaller
from utils.session import get_session_state, update_session_state


def init_mimic_engine():
    """åˆå§‹åŒ–æ¨¡ä»¿å¼•æ“"""
    state = get_session_state()
    
    if state.get('mimic_engine') is None:
        llm_caller = LLMCaller(
            api_key=state.get('api_key'),
            base_url=state.get('api_base_url'),
            model=state.get('model')
        )
        engine = MimicEngine(llm_caller=llm_caller)
        update_session_state('mimic_engine', engine)
        return engine
    
    return state.get('mimic_engine')


def get_statistics():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    try:
        engine = init_mimic_engine()
        stats = asyncio.run(engine.vector_store.get_statistics())
        return (
            stats.get('count', 0),
            len(stats.get('sources', {})),
            "âœ… æ­£å¸¸"
        )
    except:
        return 0, 0, "âš ï¸ æœªåˆå§‹åŒ–"


def chat_response(message, history):
    """ç”Ÿæˆå¯¹è¯å“åº”ï¼ˆæµå¼ï¼‰"""
    state = get_session_state()
    
    if not state.get('is_configured'):
        gr.Warning("âš ï¸ è¯·å…ˆåœ¨é…ç½®é¡µé¢è®¾ç½® API Key")
        return history
    
    if not message or not message.strip():
        return history
    
    try:
        engine = init_mimic_engine()
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        history = history + [{"role": "user", "content": message}]
        
        # æµå¼ç”ŸæˆåŠ©æ‰‹å›å¤
        assistant_message = ""
        
        # å®šä¹‰å¼‚æ­¥ç”Ÿæˆå™¨
        async def async_generate():
            nonlocal assistant_message
            async for chunk in engine.generate_response_stream(
                prompt=message,
                temperature=0.8,
                use_history=True
            ):
                assistant_message += chunk
                # æ›´æ–°å†å²è®°å½•ï¼Œæ˜¾ç¤ºå½“å‰ç”Ÿæˆçš„å†…å®¹
                current_history = history + [{"role": "assistant", "content": assistant_message}]
                yield current_history
        
        # è¿è¡Œå¼‚æ­¥ç”Ÿæˆå™¨
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        final_history = history
        try:
            gen = async_generate()
            while True:
                try:
                    current_history = loop.run_until_complete(gen.__anext__())
                    final_history = current_history
                    yield current_history
                except StopAsyncIteration:
                    break
        finally:
            loop.close()
        
        # å­¦ä¹ è¿™æ¬¡å¯¹è¯
        if assistant_message:
            asyncio.run(engine.learn_from_conversation(
                user_message=message,
                context=assistant_message
            ))
        
        return final_history
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        gr.Error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
        return history


def upload_and_learn(file):
    """ä¸Šä¼ å¹¶å­¦ä¹ èŠå¤©è®°å½•"""
    state = get_session_state()
    
    if not state.get('is_configured'):
        gr.Warning("âš ï¸ è¯·å…ˆåœ¨é…ç½®é¡µé¢è®¾ç½® API Key")
        return "âš ï¸ è¯·å…ˆé…ç½® API Key", None
    
    if file is None:
        gr.Warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶")
        return "è¯·å…ˆä¸Šä¼ æ–‡ä»¶", None
    
    try:
        engine = init_mimic_engine()
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        if hasattr(file, 'name'):
            file_path = file.name
        else:
            file_path = file
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŒ‰è¡Œåˆ†å‰²
        lines = content.split('\n')
        messages = [line.strip() for line in lines if line.strip()]
        
        # å­¦ä¹ æ¯æ¡æ¶ˆæ¯
        for msg in messages:
            asyncio.run(engine.learn_from_conversation(
                user_message=msg,
                metadata={"source": "uploaded_chat"}
            ))
        
        gr.Info(f"âœ… å·²å­¦ä¹  {len(messages)} æ¡æ¶ˆæ¯ï¼")
        return f"âœ… å·²å­¦ä¹  {len(messages)} æ¡æ¶ˆæ¯ï¼", None  # æ¸…ç©ºæ–‡ä»¶è¾“å…¥
    
    except Exception as e:
        gr.Error(f"å­¦ä¹ å¤±è´¥: {str(e)}")
        return f"âŒ å­¦ä¹ å¤±è´¥: {str(e)}", None


def create_mem_tab():
    """åˆ›å»º MEM å¯¹è¯é¡µé¢"""
    
    gr.Markdown(
        """
        ## ğŸ’¬ MEM å¯¹è¯
        
        ä¸ AI åˆ†èº«å¯¹è¯ï¼Œå®ƒä¼šæ¨¡ä»¿ä½ çš„è¯´è¯é£æ ¼ã€‚ä¸Šä¼ èŠå¤©è®°å½•è®©å®ƒå­¦ä¹ ï¼Œå¯¹è¯ä¼šè¢«è®°å½•ä»¥æŒç»­æ”¹è¿›ã€‚
        """
    )
    
    # ç»Ÿè®¡ä¿¡æ¯å¡ç‰‡
    with gr.Row():
        memory_count = gr.Number(label="ğŸ’¬ æ€»è®°å¿†æ•°", value=0, interactive=False)
        source_count = gr.Number(label="ğŸ·ï¸ æ¥æºç±»å‹", value=0, interactive=False)
        status_text = gr.Textbox(label="ğŸ“Š çŠ¶æ€", value="", interactive=False)
        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°ç»Ÿè®¡", size="sm")
    
    refresh_btn.click(
        fn=get_statistics,
        outputs=[memory_count, source_count, status_text]
    )
    
    gr.Markdown("---")
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    with gr.Tabs():
        
        # å¯¹è¯æ ‡ç­¾é¡µ
        with gr.TabItem("ğŸ’¬ å¯¹è¯"):
            
            # èŠå¤©ç•Œé¢
            chatbot = gr.Chatbot(
                label="AI åˆ†èº«å¯¹è¯",
                height=500,
                type="messages",
                avatar_images=(None, "ğŸ¤–")
            )
            
            msg_input = gr.Textbox(
                placeholder="è¾“å…¥æ¶ˆæ¯...",
                show_label=False,
                container=False
            )
            
            with gr.Row():
                send_btn = gr.Button("ğŸ“¤ å‘é€", variant="primary")
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯")
            
            # ç»‘å®šäº‹ä»¶ - æ·»åŠ æ¸…ç©ºè¾“å…¥æ¡†
            def submit_and_clear(message, history):
                # è¿”å›ç©ºå­—ç¬¦ä¸²æ¸…ç©ºè¾“å…¥æ¡†
                return "", history
            
            msg_input.submit(
                fn=submit_and_clear,
                inputs=[msg_input, chatbot],
                outputs=[msg_input, chatbot],
            ).then(
                fn=chat_response,
                inputs=[msg_input, chatbot],
                outputs=[chatbot],
            )
            
            send_btn.click(
                fn=submit_and_clear,
                inputs=[msg_input, chatbot],
                outputs=[msg_input, chatbot],
            ).then(
                fn=chat_response,
                inputs=[msg_input, chatbot],
                outputs=[chatbot],
            )
            
            clear_btn.click(
                fn=lambda: [],
                outputs=[chatbot]
            )
        
        # å­¦ä¹ ææ–™æ ‡ç­¾é¡µ
        with gr.TabItem("ğŸ“š å­¦ä¹ ææ–™"):
            
            gr.Markdown(
                """
                ### ä¸Šä¼ èŠå¤©è®°å½•
                
                ä¸Šä¼ ä½ çš„èŠå¤©è®°å½•æ–‡æœ¬æ–‡ä»¶ï¼Œè®© AI å­¦ä¹ ä½ çš„è¯´è¯é£æ ¼ã€‚
                
                **æ”¯æŒæ ¼å¼**ï¼š
                - çº¯æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€æ¡æ¶ˆæ¯ï¼‰
                - JSON æ ¼å¼çš„èŠå¤©è®°å½•
                """
            )
            
            file_upload = gr.File(
                label="é€‰æ‹©èŠå¤©è®°å½•æ–‡ä»¶",
                file_types=[".txt", ".json"],
                type="filepath"
            )
            
            upload_btn = gr.Button("ğŸ“š å¼€å§‹å­¦ä¹ ", variant="primary")
            upload_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
            
            upload_btn.click(
                fn=upload_and_learn,
                inputs=[file_upload],
                outputs=[upload_status, file_upload]  # æ¸…ç©ºæ–‡ä»¶è¾“å…¥
            )
            
            gr.Markdown("---")
            
            gr.Markdown("### âœï¸ æ‰‹åŠ¨è¾“å…¥")
            
            manual_text = gr.Textbox(
                label="è¾“å…¥ä¸€æ®µä½ è¯´è¿‡çš„è¯",
                placeholder="è¾“å…¥ä½ çš„èŠå¤©è®°å½•ã€æ—¥è®°ã€æƒ³æ³•...",
                lines=5
            )
            
            manual_btn = gr.Button("ğŸ’¾ ä¿å­˜å¹¶å­¦ä¹ ")
            manual_status = gr.Textbox(label="çŠ¶æ€", interactive=False, show_label=False)
            
            def learn_manual(text):
                if not text.strip():
                    gr.Warning("è¯·è¾“å…¥å†…å®¹")
                    return "è¯·è¾“å…¥å†…å®¹", text
                
                try:
                    engine = init_mimic_engine()
                    asyncio.run(engine.learn_from_conversation(
                        user_message=text,
                        metadata={"source": "manual_input"}
                    ))
                    gr.Info("âœ… å·²å­¦ä¹ ï¼")
                    return "âœ… å·²å­¦ä¹ ï¼", ""  # æ¸…ç©ºè¾“å…¥æ¡†
                except Exception as e:
                    gr.Error(f"å¤±è´¥: {str(e)}")
                    return f"âŒ å¤±è´¥: {str(e)}", text
            
            manual_btn.click(
                fn=learn_manual,
                inputs=[manual_text],
                outputs=[manual_status, manual_text]  # æ¸…ç©ºæ–‡æœ¬è¾“å…¥
            )
    
    # åŠ è½½æ—¶åˆ·æ–°ç»Ÿè®¡
    gr.on(
        triggers=[],
        fn=get_statistics,
        outputs=[memory_count, source_count, status_text]
    )
